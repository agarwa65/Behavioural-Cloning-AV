{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Cropping2D, Dense, Dropout, Activation, Flatten, Convolution2D, Input, Lambda, SpatialDropout2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "\n",
    "PATH = \"divya_data/\"\n",
    "IMG_PATH = \"divya_data/IMG/\"\n",
    "DATA_PATH = os.path.join(PATH, \"driving_log.csv\")\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "correction = 0.18\n",
    "validation_split = 0.2\n",
    "\n",
    "lines = []\n",
    "images = []\n",
    "measurements =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Function below describes the CNN model to be used for Behaviour Cloning\n",
    "def nvidia_model():\n",
    "    \"\"\"Ref: Nvidia paper http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\"\"\"\n",
    "    \n",
    "    def image_resize(img):\n",
    "        \n",
    "        import tensorflow as tf\n",
    "        return tf.image.resize_images(img, (66,200))\n",
    "\n",
    "    model = Sequential()\n",
    "    # Cropping the input images\n",
    "    model.add(Cropping2D(cropping=((60,25), (0,0)), input_shape=(160,320,3)))\n",
    "    # Resizing input images Output : 66x200\n",
    "    # model.add(Lambda(image_resize))\n",
    "    # Normalizing the input images\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5))\n",
    "    # Convolution Layer 1 : 24x3x3 filters, RELU activation, maxpooling(2,2) and dropout\n",
    "    model.add(Convolution2D(24,3,3, activation='relu') )\n",
    "    model.add(MaxPooling2D())\n",
    "    #model.add(Dropout(0.24))\n",
    "    # Convolution Layer 2 : 48x3x3 filters, RELU activation, maxpooling(2,2) and dropout\n",
    "    model.add(Convolution2D(36,3,3, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    #model.add(Dropout(0.24))\n",
    "    # Convolution Layer 2 : 48x3x3 filters, RELU activation, maxpooling(2,2) and dropout\n",
    "    model.add(Convolution2D(48,3,3, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    #model.add(Dropout(0.24))\n",
    "    # Convolution Layer 3 : 64x3x3 filters, RELU activation, maxpooling(2,2) and dropout\n",
    "    model.add(Convolution2D(128,3,3, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    #model.add(Dropout(0.24))\n",
    "    # Flattening \n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected Layer: Output : 512 , RELU activation and dropout\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.52))\n",
    "    # Fully connected Layer: Output : 256 , RELU activation and dropout\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.52))\n",
    "    # Fully connected Layer: Output : 100 , RELU activation and dropout\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dropout(0.52)) \n",
    "    \n",
    "    #Output for Steering wheel angle control\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',loss ='mse')\n",
    "    \n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generator definition:\n",
    "def image_data_generator(input_data, batch_size):\n",
    "\n",
    "    while(1):\n",
    "        shuffle(input_data)\n",
    "        \n",
    "        #for AWS instance running or adding current path in local instance\n",
    "        for i in range(0, len(input_data), batch_size):\n",
    "            \n",
    "            images = []\n",
    "            measurements = []\n",
    "            input_batch = input_data[i:i+batch_size]\n",
    "            \n",
    "            for line in input_batch:\n",
    "                sourcepath = line[0]\n",
    "                filename = sourcepath.split('/')[-1]\n",
    "                current_path = IMG_PATH + filename\n",
    "                #print(current_path)\n",
    "                image = mpimg.imread(current_path)\n",
    "                #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                images.append(image)\n",
    "                measurement = float(line[3])\n",
    "                measurements.append(measurement)\n",
    "\n",
    "                ## Read center, left, right camera data and append it\n",
    "                steering_center = measurement\n",
    "                # create adjusted steering measurements for the side camera images\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "\n",
    "                #read in images from center, left, right cameras\n",
    "                left_sourcepath = line[1]\n",
    "                left_filename = sourcepath.split('/')[-1]\n",
    "                left_current_path = IMG_PATH + left_filename\n",
    "\n",
    "                right_sourcepath = line[2]\n",
    "                right_filename = sourcepath.split('/')[-1]\n",
    "                right_current_path = IMG_PATH + right_filename\n",
    "\n",
    "                # add images and angles to data set\n",
    "                #images.append(cv2.cvtColor(cv2.imread(left_current_path),cv2.COLOR_BGR2RGB)) \n",
    "                #images.append(cv2.cvtColor(cv2.imread(right_current_path),cv2.COLOR_BGR2RGB))\n",
    "                images.append((mpimg.imread(left_current_path))) \n",
    "                images.append((mpimg.imread(right_current_path)))\n",
    "                measurements.append(steering_left)\n",
    "                measurements.append(steering_right)\n",
    "                \n",
    "                ##Augmenting training data\n",
    "                aug_images, aug_measurements = augment_image(images,measurements)\n",
    "                \n",
    "                ## Reducing low steering angle data \n",
    "                aug_images, aug_measurements, rem_list_rev = remove_low_steering_angle_data(aug_images, aug_measurements)\n",
    "\n",
    "            #convert to numpy arrays\n",
    "            dataX = np.array(aug_images)\n",
    "            dataY = np.array(aug_measurements)\n",
    "            \n",
    "            yield shuffle(dataX, dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original training/validation data: 9468 2368\n"
     ]
    }
   ],
   "source": [
    "##Read input from csv file generated by simulator\n",
    "with open(DATA_PATH) as csv_file:\n",
    "    reader = csv.reader(csv_file)   \n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "# skip header row  \n",
    "input_lines = lines[1:]\n",
    "\n",
    "## Split training and validation datasets\n",
    "training_count = int(0.8 * len(input_lines))\n",
    "# training_data = input_lines[:training_count]\n",
    "# validation_data = input_lines[training_count:]\n",
    "\n",
    "training_data, validation_data = train_test_split(input_lines, train_size= training_count, random_state=42)\n",
    "print(\"Length of original training/validation data:\", len(training_data), len(validation_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 0.03855, saving model to model_aws.h5\n",
      "23s - loss: 0.0460 - val_loss: 0.0386\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_loss did not improve\n",
      "15s - loss: 0.0419 - val_loss: 0.0436\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_loss improved from 0.03855 to 0.03853, saving model to model_aws.h5\n",
      "13s - loss: 0.0396 - val_loss: 0.0385\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_loss improved from 0.03853 to 0.03656, saving model to model_aws.h5\n",
      "12s - loss: 0.0409 - val_loss: 0.0366\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_loss improved from 0.03656 to 0.03598, saving model to model_aws.h5\n",
      "12s - loss: 0.0407 - val_loss: 0.0360\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_loss did not improve\n",
      "12s - loss: 0.0379 - val_loss: 0.0462\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_loss did not improve\n",
      "12s - loss: 0.0408 - val_loss: 0.0370\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_loss improved from 0.03598 to 0.03526, saving model to model_aws.h5\n",
      "12s - loss: 0.0381 - val_loss: 0.0353\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_loss did not improve\n",
      "12s - loss: 0.0372 - val_loss: 0.0388\n",
      "Epoch 10/100\n",
      "Epoch 00009: val_loss did not improve\n",
      "11s - loss: 0.0406 - val_loss: 0.0453\n",
      "Epoch 11/100\n",
      "Epoch 00010: val_loss did not improve\n",
      "12s - loss: 0.0393 - val_loss: 0.0378\n",
      "Epoch 12/100\n",
      "Epoch 00011: val_loss did not improve\n",
      "11s - loss: 0.0392 - val_loss: 0.0370\n",
      "Epoch 13/100\n",
      "Epoch 00012: val_loss did not improve\n",
      "12s - loss: 0.0410 - val_loss: 0.0372\n",
      "Epoch 14/100\n",
      "Epoch 00013: val_loss did not improve\n",
      "11s - loss: 0.0393 - val_loss: 0.0443\n",
      "Epoch 15/100\n",
      "Epoch 00014: val_loss did not improve\n",
      "12s - loss: 0.0389 - val_loss: 0.0383\n",
      "Epoch 16/100\n",
      "Epoch 00015: val_loss improved from 0.03526 to 0.03429, saving model to model_aws.h5\n",
      "12s - loss: 0.0402 - val_loss: 0.0343\n",
      "Epoch 17/100\n",
      "Epoch 00016: val_loss did not improve\n",
      "12s - loss: 0.0354 - val_loss: 0.0363\n",
      "Epoch 18/100\n",
      "Epoch 00017: val_loss did not improve\n",
      "12s - loss: 0.0391 - val_loss: 0.0432\n",
      "Epoch 19/100\n",
      "Epoch 00018: val_loss did not improve\n",
      "12s - loss: 0.0401 - val_loss: 0.0378\n",
      "Epoch 20/100\n",
      "Epoch 00019: val_loss did not improve\n",
      "12s - loss: 0.0378 - val_loss: 0.0344\n",
      "Epoch 21/100\n",
      "Epoch 00020: val_loss did not improve\n",
      "13s - loss: 0.0376 - val_loss: 0.0398\n",
      "Epoch 22/100\n",
      "Epoch 00021: val_loss did not improve\n",
      "13s - loss: 0.0390 - val_loss: 0.0388\n",
      "Epoch 23/100\n",
      "Epoch 00022: val_loss did not improve\n",
      "12s - loss: 0.0389 - val_loss: 0.0398\n",
      "Epoch 24/100\n",
      "Epoch 00023: val_loss improved from 0.03429 to 0.03260, saving model to model_aws.h5\n",
      "12s - loss: 0.0391 - val_loss: 0.0326\n",
      "Epoch 25/100\n",
      "Epoch 00024: val_loss did not improve\n",
      "11s - loss: 0.0397 - val_loss: 0.0416\n",
      "Epoch 26/100\n",
      "Epoch 00025: val_loss did not improve\n",
      "12s - loss: 0.0360 - val_loss: 0.0375\n",
      "Epoch 27/100\n",
      "Epoch 00026: val_loss did not improve\n",
      "12s - loss: 0.0395 - val_loss: 0.0387\n",
      "Epoch 28/100\n",
      "Epoch 00027: val_loss did not improve\n",
      "12s - loss: 0.0381 - val_loss: 0.0363\n",
      "Epoch 29/100\n",
      "Epoch 00028: val_loss did not improve\n",
      "12s - loss: 0.0363 - val_loss: 0.0442\n",
      "Epoch 30/100\n",
      "Epoch 00029: val_loss did not improve\n",
      "11s - loss: 0.0381 - val_loss: 0.0387\n",
      "Epoch 31/100\n",
      "Epoch 00030: val_loss did not improve\n",
      "12s - loss: 0.0380 - val_loss: 0.0390\n",
      "Epoch 32/100\n",
      "Epoch 00031: val_loss did not improve\n",
      "12s - loss: 0.0380 - val_loss: 0.0371\n",
      "Epoch 33/100\n",
      "Epoch 00032: val_loss did not improve\n",
      "12s - loss: 0.0375 - val_loss: 0.0434\n",
      "Epoch 34/100\n",
      "Epoch 00033: val_loss did not improve\n",
      "12s - loss: 0.0380 - val_loss: 0.0364\n",
      "Epoch 35/100\n",
      "Epoch 00034: val_loss did not improve\n",
      "11s - loss: 0.0349 - val_loss: 0.0366\n",
      "Epoch 36/100\n",
      "Epoch 00035: val_loss did not improve\n",
      "11s - loss: 0.0394 - val_loss: 0.0365\n",
      "Epoch 37/100\n",
      "Epoch 00036: val_loss did not improve\n",
      "12s - loss: 0.0376 - val_loss: 0.0416\n",
      "Epoch 38/100\n",
      "Epoch 00037: val_loss did not improve\n",
      "12s - loss: 0.0376 - val_loss: 0.0387\n",
      "Epoch 39/100\n",
      "Epoch 00038: val_loss did not improve\n",
      "12s - loss: 0.0369 - val_loss: 0.0393\n",
      "Epoch 40/100\n",
      "Epoch 00039: val_loss did not improve\n",
      "12s - loss: 0.0364 - val_loss: 0.0342\n",
      "Epoch 41/100\n",
      "Epoch 00040: val_loss did not improve\n",
      "12s - loss: 0.0359 - val_loss: 0.0406\n",
      "Epoch 42/100\n",
      "Epoch 00041: val_loss did not improve\n",
      "12s - loss: 0.0364 - val_loss: 0.0395\n",
      "Epoch 43/100\n",
      "Epoch 00042: val_loss did not improve\n",
      "12s - loss: 0.0387 - val_loss: 0.0360\n",
      "Epoch 44/100\n",
      "Epoch 00043: val_loss did not improve\n",
      "12s - loss: 0.0352 - val_loss: 0.0368\n",
      "Epoch 45/100\n",
      "Epoch 00044: val_loss did not improve\n",
      "12s - loss: 0.0368 - val_loss: 0.0448\n",
      "Epoch 00044: early stopping\n"
     ]
    }
   ],
   "source": [
    "##Create model\n",
    "model = nvidia_model()\n",
    "\n",
    "# File to save the learned model\n",
    "filepath=\"model_aws.h5\"\n",
    "# Callbacks for saving the model when val loss decreases\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "#Early termination if val loss is not reducing uptil next 20 epochs\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "training_datagen = image_data_generator(training_data, BATCH_SIZE)\n",
    "validation_datagen = image_data_generator(validation_data, BATCH_SIZE)\n",
    "samples_per_epoch = int(len(training_data) )\n",
    "nb_val_samples = len(validation_data)\n",
    "\n",
    "#Training the model using keras fit \n",
    "history_values = model.fit_generator(training_datagen, samples_per_epoch = samples_per_epoch, validation_data = validation_datagen, nb_epoch = EPOCHS, nb_val_samples=nb_val_samples, callbacks=callbacks_list, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ### print the keys contained in the history object\n",
    "# print(history_values.history.keys())\n",
    "\n",
    "# ### plot the training and validation loss for each epoch\n",
    "# plt.plot(history_values.history['loss'])\n",
    "# plt.plot(history_values.history['val_loss'])\n",
    "# plt.title('model mean squared error loss')\n",
    "# plt.ylabel('mean squared error loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
